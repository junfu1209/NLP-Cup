{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65d8a27",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:13.582011Z",
     "iopub.status.busy": "2024-12-07T21:33:13.581707Z",
     "iopub.status.idle": "2024-12-07T21:33:36.763046Z",
     "shell.execute_reply": "2024-12-07T21:33:36.761973Z"
    },
    "papermill": {
     "duration": 23.190122,
     "end_time": "2024-12-07T21:33:36.765200",
     "exception": false,
     "start_time": "2024-12-07T21:33:13.575078",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ../input/sentence-transformers-123\r\n",
      "Processing /kaggle/input/sentence-transformers-123/sentence_transformers-3.1.1-py3-none-any.whl (from -r ../input/sentence-transformers-123/requirements.txt (line 1))\r\n",
      "Processing /kaggle/input/sentence-transformers-123/transformers-4.39.2-py3-none-any.whl (from -r ../input/sentence-transformers-123/requirements.txt (line 2))\r\n",
      "Processing /kaggle/input/sentence-transformers-123/peft-0.9.0-py3-none-any.whl (from -r ../input/sentence-transformers-123/requirements.txt (line 3))\r\n",
      "Processing /kaggle/input/sentence-transformers-123/bitsandbytes-0.42.0-py3-none-any.whl (from -r ../input/sentence-transformers-123/requirements.txt (line 4))\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (0.22.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (4.66.1)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (5.9.3)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (2.1.2)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (0.28.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0->-r ../input/sentence-transformers-123/requirements.txt (line 4)) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->-r ../input/sentence-transformers-123/requirements.txt (line 1)) (1.2.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->-r ../input/sentence-transformers-123/requirements.txt (line 1)) (9.5.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (2024.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (3.1.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.2->-r ../input/sentence-transformers-123/requirements.txt (line 2)) (2024.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->-r ../input/sentence-transformers-123/requirements.txt (line 1)) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->-r ../input/sentence-transformers-123/requirements.txt (line 1)) (3.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.9.0->-r ../input/sentence-transformers-123/requirements.txt (line 3)) (1.3.0)\r\n",
      "Installing collected packages: bitsandbytes, transformers, sentence_transformers, peft\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.39.3\r\n",
      "    Uninstalling transformers-4.39.3:\r\n",
      "      Successfully uninstalled transformers-4.39.3\r\n",
      "Successfully installed bitsandbytes-0.42.0 peft-0.9.0 sentence_transformers-3.1.1 transformers-4.39.2\r\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install --no-index --find-links=../input/sentence-transformers-123 -r ../input/sentence-transformers-123/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b9f2d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:36.778307Z",
     "iopub.status.busy": "2024-12-07T21:33:36.778031Z",
     "iopub.status.idle": "2024-12-07T21:33:54.213710Z",
     "shell.execute_reply": "2024-12-07T21:33:54.213014Z"
    },
    "papermill": {
     "duration": 17.444358,
     "end_time": "2024-12-07T21:33:54.215640",
     "exception": false,
     "start_time": "2024-12-07T21:33:36.771282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 21:33:46.866588: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-07 21:33:46.866731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-07 21:33:46.996207: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, T5Tokenizer, AutoModelForCausalLM, T5ForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39646fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.228399Z",
     "iopub.status.busy": "2024-12-07T21:33:54.227912Z",
     "iopub.status.idle": "2024-12-07T21:33:54.231597Z",
     "shell.execute_reply": "2024-12-07T21:33:54.230939Z"
    },
    "papermill": {
     "duration": 0.011472,
     "end_time": "2024-12-07T21:33:54.233070",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.221598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 0\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332c7258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.245062Z",
     "iopub.status.busy": "2024-12-07T21:33:54.244859Z",
     "iopub.status.idle": "2024-12-07T21:33:54.272764Z",
     "shell.execute_reply": "2024-12-07T21:33:54.272024Z"
    },
    "papermill": {
     "duration": 0.035483,
     "end_time": "2024-12-07T21:33:54.274322",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.238839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The competition dataset comprises text passage...</td>\n",
       "      <td>Convert this into a sea shanty: \"\"\"The competi...</td>\n",
       "      <td>Here is your shanty: (Verse 1) The text is rew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      original_text  \\\n",
       "0  -1  The competition dataset comprises text passage...   \n",
       "\n",
       "                                      rewrite_prompt  \\\n",
       "0  Convert this into a sea shanty: \"\"\"The competi...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Here is your shanty: (Verse 1) The text is rew...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/llm-prompt-recovery/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/llm-prompt-recovery/test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0076ecaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.287154Z",
     "iopub.status.busy": "2024-12-07T21:33:54.286554Z",
     "iopub.status.idle": "2024-12-07T21:33:54.320010Z",
     "shell.execute_reply": "2024-12-07T21:33:54.319440Z"
    },
    "papermill": {
     "duration": 0.041421,
     "end_time": "2024-12-07T21:33:54.321624",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.280203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt_dataset\n",
    "data = pd.read_csv(\"/kaggle/input/concat-prompts/prompts.csv\")\n",
    "prompt_dataset = data['prompt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c6e853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.334921Z",
     "iopub.status.busy": "2024-12-07T21:33:54.334712Z",
     "iopub.status.idle": "2024-12-07T21:33:54.338172Z",
     "shell.execute_reply": "2024-12-07T21:33:54.337334Z"
    },
    "papermill": {
     "duration": 0.01166,
     "end_time": "2024-12-07T21:33:54.340006",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.328346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "# model_path = '../input/transformers/t5-base'\n",
    "# model     = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6f3e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.352104Z",
     "iopub.status.busy": "2024-12-07T21:33:54.351902Z",
     "iopub.status.idle": "2024-12-07T21:33:54.355108Z",
     "shell.execute_reply": "2024-12-07T21:33:54.354451Z"
    },
    "papermill": {
     "duration": 0.011096,
     "end_time": "2024-12-07T21:33:54.356713",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.345617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Vocabulary dataset\n",
    "# vocabulary_dataset = tokenizer.get_vocab()\n",
    "# vocabulary_dataset.pop('<pad>', None)\n",
    "# vocabulary_dataset.pop('</s>', None)\n",
    "# vocabulary_dataset.pop('<unk>', None)\n",
    "# vocabulary_dataset.pop('▁', None)\n",
    "# for n in range(100):\n",
    "#     vocabulary_dataset.pop(f\"<extra_id_{n}>\", None)\n",
    "\n",
    "# vocabulary_dataset = list(vocabulary_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9bc248",
   "metadata": {
    "papermill": {
     "duration": 0.005353,
     "end_time": "2024-12-07T21:33:54.367726",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.362373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Mean Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2e0e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.379891Z",
     "iopub.status.busy": "2024-12-07T21:33:54.379655Z",
     "iopub.status.idle": "2024-12-07T21:33:54.383091Z",
     "shell.execute_reply": "2024-12-07T21:33:54.382463Z"
    },
    "papermill": {
     "duration": 0.011449,
     "end_time": "2024-12-07T21:33:54.384657",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.373208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def attack(prompt_tokens, token_index, vocabulary_dataset, model, target_embedding):\n",
    "#     prompts = []\n",
    "#     for vocab in vocabulary_dataset:\n",
    "#         prompt = ''.join(prompt_tokens[:token_index] + [vocab] + prompt_tokens[token_index + 1:])\n",
    "#         prompt = prompt.replace('▁', ' ')\n",
    "#         prompts.append(prompt)\n",
    "\n",
    "#     prompt_embeddings = torch.tensor(np.array(model.encode(prompts)), dtype=torch.float32)\n",
    "\n",
    "#     simularities = cosine_similarity(target_embedding, prompt_embeddings)\n",
    "\n",
    "#     vocab_index = simularities.argmax().item()\n",
    "#     prompt_tokens[token_index] = vocabulary_dataset[vocab_index]\n",
    "\n",
    "#     return prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a57191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.396668Z",
     "iopub.status.busy": "2024-12-07T21:33:54.396416Z",
     "iopub.status.idle": "2024-12-07T21:33:54.399764Z",
     "shell.execute_reply": "2024-12-07T21:33:54.399124Z"
    },
    "papermill": {
     "duration": 0.011041,
     "end_time": "2024-12-07T21:33:54.401288",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.390247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model_path = '/kaggle/input/sentence-t5-base/transformers/llm-prompt-recovery/1' \n",
    "# model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660eccc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.413882Z",
     "iopub.status.busy": "2024-12-07T21:33:54.413157Z",
     "iopub.status.idle": "2024-12-07T21:33:54.416209Z",
     "shell.execute_reply": "2024-12-07T21:33:54.415660Z"
    },
    "papermill": {
     "duration": 0.010942,
     "end_time": "2024-12-07T21:33:54.417865",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.406923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c279bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.430530Z",
     "iopub.status.busy": "2024-12-07T21:33:54.430045Z",
     "iopub.status.idle": "2024-12-07T21:33:54.433465Z",
     "shell.execute_reply": "2024-12-07T21:33:54.432702Z"
    },
    "papermill": {
     "duration": 0.011479,
     "end_time": "2024-12-07T21:33:54.434977",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.423498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Initial prompt\n",
    "# prompt = \"Rewrite this text to make it more helpful\"\n",
    "# prompt_embedding = model.encode(prompt)\n",
    "# prompt_embedding = torch.tensor(prompt_embedding, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# # Prompt tokens\n",
    "# prompt_tokens = prompt.split(' ')\n",
    "\n",
    "# # Target\n",
    "# target_embedding = model.encode(prompt_dataset)\n",
    "# target_embedding = torch.tensor(target_embedding, dtype=torch.float32).mean(dim=0).unsqueeze(0)\n",
    "\n",
    "# print(prompt_embedding.shape)\n",
    "# print(target_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c83d1fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.447032Z",
     "iopub.status.busy": "2024-12-07T21:33:54.446811Z",
     "iopub.status.idle": "2024-12-07T21:33:54.450245Z",
     "shell.execute_reply": "2024-12-07T21:33:54.449648Z"
    },
    "papermill": {
     "duration": 0.011303,
     "end_time": "2024-12-07T21:33:54.451907",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.440604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "#     for token_index in range(len(prompt_tokens)):\n",
    "#         prompt_tokens = attack(prompt_tokens, token_index, vocabulary_dataset, model, target_embedding)\n",
    "#         prompt = ''.join(prompt_tokens).replace('▁', ' ')\n",
    "#         print(prompt)\n",
    "\n",
    "#     prompt_embedding = model.encode(prompt)\n",
    "#     prompt_embedding = torch.tensor(prompt_embedding, dtype=torch.float32).unsqueeze(0)\n",
    "#     loss =  1 - cosine_similarity(target_embedding, prompt_embedding)\n",
    "#     print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# mean_prompt = prompt\n",
    "# print('Mean prompt:', mean_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8ac98",
   "metadata": {
    "papermill": {
     "duration": 0.00547,
     "end_time": "2024-12-07T21:33:54.463019",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.457549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee1ad5f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.475182Z",
     "iopub.status.busy": "2024-12-07T21:33:54.474964Z",
     "iopub.status.idle": "2024-12-07T21:33:54.478097Z",
     "shell.execute_reply": "2024-12-07T21:33:54.477362Z"
    },
    "papermill": {
     "duration": 0.010833,
     "end_time": "2024-12-07T21:33:54.479544",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.468711",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install ../input/hf-peft/peft-0.9.0-py3-none-any.whl\n",
    "# %pip install ../input/bitsandbytes/bitsandbytes-0.42.0-py3-none-any.whl\n",
    "# %pip install ../input/sentence-transformers/sentence_transformers/sentence_transformers-3.3.1-py3-none-any.whl\n",
    "# %pip install ../input/transformers-4-39-2/transformers-4.39.2-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63573054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.495332Z",
     "iopub.status.busy": "2024-12-07T21:33:54.495101Z",
     "iopub.status.idle": "2024-12-07T21:33:54.498847Z",
     "shell.execute_reply": "2024-12-07T21:33:54.498081Z"
    },
    "papermill": {
     "duration": 0.015191,
     "end_time": "2024-12-07T21:33:54.500357",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.485166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed4c9c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:54.512822Z",
     "iopub.status.busy": "2024-12-07T21:33:54.512592Z",
     "iopub.status.idle": "2024-12-07T21:33:55.551038Z",
     "shell.execute_reply": "2024-12-07T21:33:55.549993Z"
    },
    "papermill": {
     "duration": 1.046756,
     "end_time": "2024-12-07T21:33:55.553073",
     "exception": false,
     "start_time": "2024-12-07T21:33:54.506317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../input/llm-prompt-recovery/test.csv\")\n",
    "!cp ../input/llm-prompt-recovery/test.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6add0371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:55.567014Z",
     "iopub.status.busy": "2024-12-07T21:33:55.566725Z",
     "iopub.status.idle": "2024-12-07T21:33:55.577053Z",
     "shell.execute_reply": "2024-12-07T21:33:55.576103Z"
    },
    "papermill": {
     "duration": 0.019687,
     "end_time": "2024-12-07T21:33:55.578829",
     "exception": false,
     "start_time": "2024-12-07T21:33:55.559142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.py\n",
    "\n",
    "# !cp ../input/recovery-scripts/run.py .\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from peft import PeftModel, PeftConfig\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "# Create the argument parser\n",
    "parser = argparse.ArgumentParser(description=\"\")\n",
    "\n",
    "parser.add_argument(\"--model_path\", type=str, help=\"\")\n",
    "parser.add_argument(\"--peft_path\", type=str, help=\"\", default=\"\")\n",
    "parser.add_argument(\"--model_type\", type=str, help=\"\")\n",
    "parser.add_argument(\"--prime\", type=str, help=\"\", default=\"\")\n",
    "parser.add_argument(\"--magic\", type=str, help=\"\", default=\"\")\n",
    "parser.add_argument(\"--output\", type=str, help=\"\")\n",
    "parser.add_argument(\"--max_len\", type=int, help=\"\")\n",
    "parser.add_argument(\"--min_output_len\", type=int, help=\"\", default=2)\n",
    "parser.add_argument(\"--max_output_len\", type=int, help=\"\", default=100)\n",
    "parser.add_argument('--quantize', action='store_true')\n",
    "parser.add_argument('--do_sample', action='store_true')\n",
    "parser.add_argument('--test_path', type=str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "test = pd.read_csv(args.test_path)\n",
    "magic = \"Transform the following text in a more vivid and descriptive way, while maintaining the original meaning and tone.\"\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "lucrarea = args.magic\n",
    "def predict_gemma(model, tokenizer, test, bad_words_ids=None):\n",
    "    if bad_words_ids is not None and len(bad_words_ids) == 0:\n",
    "        bad_words_ids = None\n",
    "    predictions = []\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "            if row.original_text == row.rewritten_text:\n",
    "                predictions.append(\"Correct grammatical errors in this text.\")\n",
    "                continue\n",
    "            ot = \" \".join(str(row.original_text).split(\" \")[:args.max_len])\n",
    "            rt = \" \".join(str(row.rewritten_text).split(\" \")[:args.max_len])\n",
    "            prompt = f\"Find the orginal prompt that transformed original text to new text.\\n\\nOriginal text: {ot}\\n====\\nNew text: {rt}\"\n",
    "            conversation = [{\"role\": \"user\", \"content\": prompt }]\n",
    "            prime = args.prime\n",
    "            prompt = tokenizer.apply_chat_template(conversation, tokenize=False) + f\"<start_of_turn>model\\n{prime}\"\n",
    "            input_ids = tokenizer.encode(prompt, add_special_tokens=False, truncation=True, max_length=1536,padding=False,return_tensors=\"pt\")\n",
    "            x = model.generate(input_ids=input_ids.to(model.device), eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.eos_token_id, max_new_tokens=128, do_sample=args.do_sample, early_stopping=True, num_beams=1, bad_words_ids=bad_words_ids)\n",
    "            try:\n",
    "                x = tokenizer.decode(x[0]).split(\"<start_of_turn>model\")[1].split(\"<end_of_turn>\")[0].replace(\"<end_of_turn>\\n<eos>\",\"\").replace(\"<end_of_turn>\",\"\").replace(\"<start_of_turn>\",\"\").replace(\"<eos>\",\"\").replace(\"<bos>\",\"\").strip().replace('\"','').strip()\n",
    "                x = x.replace(\"Can you make this\",\"Make this\").replace(\"?\",\".\").replace(\"Revise\",\"Rewrite\")\n",
    "                x = x.split(\":\",1)[-1].strip()\n",
    "                if \"useruser\" in x:\n",
    "                    x = x.replace(\"user\",\"\")\n",
    "                if x[-1].isalnum():\n",
    "                    x += \".\"\n",
    "                else:\n",
    "                    x = x[:-1]+\".\"\n",
    "                x+= lucrarea\n",
    "                if len(x.split()) < args.max_output_len and len(x.split()) > args.min_output_len and (\"\\n\" not in x):\n",
    "                    print(x)\n",
    "                    predictions.append(x)\n",
    "                else:\n",
    "                    predictions.append(magic)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                predictions.append(magic)\n",
    "    return predictions\n",
    "\n",
    "def predict_mistral(model, tokenizer, test,prime=\"\"):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "            ot = \" \".join(str(row.original_text).split(\" \")[:args.max_len])\n",
    "            rt = \" \".join(str(row.rewritten_text).split(\" \")[:args.max_len])\n",
    "            prompt = f'''\n",
    "Please find the prompt that was given to you to transform **original_text** to **new_text**. One clue is the prompt itself was short and concise.\n",
    "Answer in thist format: \"It's likely that the prompt that transformed original_text to new_text was: <the prompt>\" and don't add anything else.\n",
    "\n",
    "**original_text**:\n",
    "{ot}\n",
    "\n",
    "**new_text**:\n",
    "{rt}\n",
    "'''\n",
    "            conversation = [{\"role\": \"user\", \"content\": prompt }]\n",
    "            prompt = tokenizer.apply_chat_template(conversation, tokenize=False)+prime\n",
    "            input_ids = tokenizer.encode(prompt, add_special_tokens=False, truncation=True, max_length=1536,padding=False,return_tensors=\"pt\")\n",
    "            x = model.generate(input_ids=input_ids.to(model.device), eos_token_id=[13, tokenizer.eos_token_id], pad_token_id=tokenizer.eos_token_id, max_new_tokens=32, do_sample=args.do_sample, early_stopping=True, num_beams=1)\n",
    "            try:\n",
    "                x = tokenizer.decode(x[0]).split(\"[/INST]\")[-1].replace(\"</s>\",\"\").strip().split(\"\\n\",1)[0]\n",
    "                x = x.replace(\"Can you make this\",\"Make this\").replace(\"?\",\".\")\n",
    "                # print(x.split(\":\",1)[0])\n",
    "                x = x.split(\":\",1)[-1].strip()\n",
    "                if x[-1].isalnum():\n",
    "                    x += \".\"\n",
    "                else:\n",
    "                    x = x[:-1]+\".\"\n",
    "                x += lucrarea\n",
    "                if len(x.split()) < 50 and len(x.split()) > 2 and (\"\\n\" not in x):\n",
    "                    predictions.append(x)\n",
    "                else:\n",
    "                    predictions.append(magic)\n",
    "                print(predictions[-1])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                predictions.append(magic)\n",
    "    return predictions\n",
    "model_name = args.model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "banned_ids = None\n",
    "    \n",
    "if args.quantize:\n",
    "    print(\"Use 4bit quantization\")\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                 quantization_config=quantization_config,\n",
    "                                                 device_map=\"auto\",\n",
    "                                                 torch_dtype=torch.bfloat16)\n",
    "    if args.peft_path != \"\":\n",
    "        print(\"Use peft\")\n",
    "        model = PeftModel.from_pretrained(model,\n",
    "                                    args.peft_path,\n",
    "                                    quantization_config=quantization_config,\n",
    "                                    torch_dtype=torch.bfloat16,\n",
    "                                    device_map=\"auto\")\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                 device_map=\"auto\",\n",
    "                                                 torch_dtype=torch.bfloat16)\n",
    "    if args.peft_path != \"\":\n",
    "        print(\"Use peft\")\n",
    "        model = PeftModel.from_pretrained(model,\n",
    "                                args.peft_path,\n",
    "                                torch_dtype=torch.bfloat16,\n",
    "                                device_map=\"auto\")\n",
    "        \n",
    "# model = model.merge_and_unload()\n",
    "model.eval()\n",
    "# print(model)\n",
    "if args.model_type == \"gemma\":\n",
    "    preds = predict_gemma(model, tokenizer, test, bad_words_ids=banned_ids)\n",
    "elif args.model_type == \"mistral\":\n",
    "    preds = predict_mistral(model, tokenizer, test, prime=args.prime)\n",
    "\n",
    "json.dump(preds, open(args.output,\"wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0083884b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:33:55.591015Z",
     "iopub.status.busy": "2024-12-07T21:33:55.590777Z",
     "iopub.status.idle": "2024-12-07T21:36:01.376695Z",
     "shell.execute_reply": "2024-12-07T21:36:01.375467Z"
    },
    "papermill": {
     "duration": 125.794414,
     "end_time": "2024-12-07T21:36:01.378826",
     "exception": false,
     "start_time": "2024-12-07T21:33:55.584412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 4bit quantization\r\n",
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\r\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:49<00:00, 27.32s/it]\r\n",
      "Use peft\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\r\n",
      "  warnings.warn(\r\n",
      "2024-12-07 21:35:55.460514: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-12-07 21:35:55.460572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-12-07 21:35:55.461981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Improve this text using the writing style of a sea shanty.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.35s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_path /kaggle/input/gemma/transformers/7b-it/3/ --peft_path \"../input/gemma-7b-orca-68500/\" --model_type \"gemma\" --output \"pred2.json\" --max_len 512 --test_path ./test.csv --quantize --prime \"General prompt: Improve this text using the writing style\"\n",
    "preds = json.load(open(\"pred2.json\"))\n",
    "# preds = [\"Please improve this text using the writing style with maintaining the original meaning but altering the tone.\",]*len(test)\n",
    "def remove_pp(x):\n",
    "    for w in x.split()[1:]:\n",
    "        if w.istitle():\n",
    "            return \"Please improve this text using the writing style.\"\n",
    "    return x\n",
    "preds = [remove_pp(x)[:-1]+\" with maintaining the original meaning but altering the tone.\" for x in preds]\n",
    "json.dump(preds, open(\"pred2.json\",\"wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c56a2f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:36:01.393896Z",
     "iopub.status.busy": "2024-12-07T21:36:01.393618Z",
     "iopub.status.idle": "2024-12-07T21:37:48.210559Z",
     "shell.execute_reply": "2024-12-07T21:37:48.209526Z"
    },
    "papermill": {
     "duration": 106.826634,
     "end_time": "2024-12-07T21:37:48.212666",
     "exception": false,
     "start_time": "2024-12-07T21:36:01.386032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 4bit quantization\r\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\r\n",
      "  return self.fget.__get__(instance, owner)()\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [01:30<00:00, 45.45s/it]\r\n",
      "Use peft\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\r\n",
      "No chat template is defined for this tokenizer - using the default template for the LlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\r\n",
      "\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\r\n",
      "  warnings.warn(\r\n",
      "2024-12-07 21:37:43.424109: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-12-07 21:37:43.424170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-12-07 21:37:43.425529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Rewrite the following text into a shanty.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.92s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model_path \"/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\" \\\n",
    "               --peft_path \"../input/mistral-og-600\" \\\n",
    "               --model_type \"mistral\" \\\n",
    "               --output \"pred0.json\" \\\n",
    "               --max_len 512 \\\n",
    "               --test_path \"./test.csv\" \\\n",
    "               --quantize \\\n",
    "               --prime \"It's likely that the prompt that transformed original_text to new_text was: Rewrite\" \\\n",
    "               --magic \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "728e00ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:48.228420Z",
     "iopub.status.busy": "2024-12-07T21:37:48.227783Z",
     "iopub.status.idle": "2024-12-07T21:39:33.559402Z",
     "shell.execute_reply": "2024-12-07T21:39:33.558273Z"
    },
    "papermill": {
     "duration": 105.341864,
     "end_time": "2024-12-07T21:39:33.561639",
     "exception": false,
     "start_time": "2024-12-07T21:37:48.219775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 4bit quantization\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [01:29<00:00, 29.90s/it]\r\n",
      "Use peft\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\r\n",
      "  warnings.warn(\r\n",
      "2024-12-07 21:39:29.202461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-12-07 21:39:29.202520: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-12-07 21:39:29.203932: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Make this text into a shanty about a code competition.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.34s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python run.py \\\n",
    "  --model_path ../input/mistral-7b-it-v02/ \\\n",
    "  --peft_path \"../input/mistral-gemmaonly\" \\\n",
    "  --model_type \"mistral\" \\\n",
    "  --output \"pred3.json\" \\\n",
    "  --max_len 512 \\\n",
    "  --test_path ./test.csv \\\n",
    "  --quantize \\\n",
    "  --prime \"It's likely that the prompt that transformed original_text to new_text was: Make this text\" \\\n",
    "  --magic \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b070ac54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:39:33.578278Z",
     "iopub.status.busy": "2024-12-07T21:39:33.577991Z",
     "iopub.status.idle": "2024-12-07T21:41:40.020841Z",
     "shell.execute_reply": "2024-12-07T21:41:40.019920Z"
    },
    "papermill": {
     "duration": 126.453803,
     "end_time": "2024-12-07T21:41:40.023139",
     "exception": false,
     "start_time": "2024-12-07T21:39:33.569336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 4bit quantization\r\n",
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\r\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:51<00:00, 27.89s/it]\r\n",
      "Use peft\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\r\n",
      "  warnings.warn(\r\n",
      "2024-12-07 21:41:35.305155: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-12-07 21:41:35.305221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-12-07 21:41:35.306614: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Alter this into a sailor's shanty.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.46s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python run.py \\\n",
    "  --model_path /kaggle/input/gemma/transformers/7b-it/3 \\\n",
    "  --peft_path \"../input/gemma-7b-orca-external/\" \\\n",
    "  --model_type \"gemma\" \\\n",
    "  --output \"pred1.json\" \\\n",
    "  --max_len 512 \\\n",
    "  --test_path ./test.csv \\\n",
    "  --quantize \\\n",
    "  --prime \"General prompt: Alter\" \\\n",
    "  --magic \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9807a6ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:41:40.040404Z",
     "iopub.status.busy": "2024-12-07T21:41:40.040137Z",
     "iopub.status.idle": "2024-12-07T21:41:40.044096Z",
     "shell.execute_reply": "2024-12-07T21:41:40.043261Z"
    },
    "papermill": {
     "duration": 0.014573,
     "end_time": "2024-12-07T21:41:40.045728",
     "exception": false,
     "start_time": "2024-12-07T21:41:40.031155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fns = [\"pred1.json\", \"pred2.json\", \"pred3.json\"]\n",
    "# preds = [json.load(open(x)) for x in fns]\n",
    "# preds = [' '.join(list(x)) for x in zip(*preds)]\n",
    "# print(preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fad5e175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:41:40.061786Z",
     "iopub.status.busy": "2024-12-07T21:41:40.061531Z",
     "iopub.status.idle": "2024-12-07T21:41:40.065200Z",
     "shell.execute_reply": "2024-12-07T21:41:40.064428Z"
    },
    "papermill": {
     "duration": 0.013396,
     "end_time": "2024-12-07T21:41:40.066740",
     "exception": false,
     "start_time": "2024-12-07T21:41:40.053344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# magic = \" 'it 's ' something Think A Human Plucrarealucrarealucrarealucrarealucrarealucrarealucrarealucrarea\"\n",
    "# # magic = \"\"\n",
    "# predictions = [x+magic for x in preds]\n",
    "\n",
    "# sub = pd.read_csv(\"../input/llm-prompt-recovery/sample_submission.csv\")\n",
    "# sub['rewrite_prompt'] = predictions\n",
    "# sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc100644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:41:40.082940Z",
     "iopub.status.busy": "2024-12-07T21:41:40.082691Z",
     "iopub.status.idle": "2024-12-07T21:41:43.378942Z",
     "shell.execute_reply": "2024-12-07T21:41:43.378252Z"
    },
    "papermill": {
     "duration": 3.306112,
     "end_time": "2024-12-07T21:41:43.380558",
     "exception": false,
     "start_time": "2024-12-07T21:41:40.074446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc68f7712eb45a898e5a6609f11ef58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6458202b25c24b6e93bea56289a87e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd36d7eb3be4d4aa397941e0ff103b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb144b0efbc40f991225fa7b30de5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "magic =  \" 'it 's ' something Think A Human Plucrarealucrarealucrarealucrarealucrarealucrarealucrarealucrarea\"\n",
    "\n",
    "def sharpened_cosine_similarity(vectors, exponent=3):\n",
    "    # 計算 Cosine Similarity\n",
    "    cosine_sim = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    sharpened_cosine = cosine_sim ** exponent\n",
    "    return sharpened_cosine\n",
    "\n",
    "def find_max_scs(sentences, model, threshold=0.75, min_scs_to_others=0.80, exponent=3):\n",
    "    \"\"\"\n",
    "    找出 SCS 最大的兩個句子，並檢查這兩個句子對其他句子的 SCS 是否大於 min_scs_to_others。\n",
    "    \n",
    "    Args:\n",
    "        sentences (list): 要處理的句子列表。\n",
    "        model: SentenceTransformer 模型，用於句子向量化。\n",
    "        threshold (float): 選擇兩個句子的 SCS 閾值。\n",
    "        min_scs_to_others (float): 返回的兩個句子對其他句子的 SCS 下限。\n",
    "        exponent (int): SCS 的指數。\n",
    "    \n",
    "    Returns:\n",
    "        str: 選出的句子對或所有句子的拼接。\n",
    "    \"\"\"\n",
    "    # 將所有句子轉換為向量\n",
    "    vectors = [model.encode(sentence) for sentence in sentences]\n",
    "    \n",
    "    max_scs = 0\n",
    "    max_pair = None\n",
    "\n",
    "    # 計算所有句子對的 SCS，選擇最大 SCS\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(i + 1, len(sentences)):  \n",
    "            scs = sharpened_cosine_similarity([vectors[i], vectors[j]], exponent)\n",
    "            if scs > max_scs:\n",
    "                max_scs = scs\n",
    "                max_pair = (i, j)  # 存儲索引而非句子內容\n",
    "\n",
    "    # 確保選出的句子對的 SCS 大於 threshold\n",
    "    if max_scs > threshold:\n",
    "        # 驗證選出的句子對與其他句子的 SCS 是否滿足 min_scs_to_others\n",
    "        valid = True\n",
    "        for k in range(len(sentences)):\n",
    "            if k not in max_pair:  # 排除句子對本身\n",
    "                scs_to_i = sharpened_cosine_similarity([vectors[max_pair[0]], vectors[k]], exponent)\n",
    "                scs_to_j = sharpened_cosine_similarity([vectors[max_pair[1]], vectors[k]], exponent)\n",
    "                if scs_to_i < min_scs_to_others or scs_to_j < min_scs_to_others:\n",
    "                    valid = False\n",
    "                    break\n",
    "        if valid:\n",
    "            return sentences[max_pair[0]] + \" \" + sentences[max_pair[1]]\n",
    "    \n",
    "    # 若不滿足條件，返回所有句子拼接\n",
    "    return \" \".join(sentences) + magic\n",
    "model_path = '/kaggle/input/sentence-t5-base/transformers/llm-prompt-recovery/1' \n",
    "model = SentenceTransformer(model_path)\n",
    "\n",
    "\n",
    "threshold = 0.83\n",
    "\n",
    "results = []\n",
    "\n",
    "fns = [\"pred0.json\",\"pred1.json\", \"pred2.json\", \"pred3.json\"]\n",
    "preds = [json.load(open(x)) for x in fns]\n",
    "for x in zip(*preds):\n",
    "    result = find_max_scs(x, model, threshold)\n",
    "    results.append(result)  \n",
    "    # print(\"Result:\", result)\n",
    "\n",
    "# print(\"All results:\", results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ad1f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:41:43.398935Z",
     "iopub.status.busy": "2024-12-07T21:41:43.398703Z",
     "iopub.status.idle": "2024-12-07T21:41:43.412394Z",
     "shell.execute_reply": "2024-12-07T21:41:43.411757Z"
    },
    "papermill": {
     "duration": 0.024547,
     "end_time": "2024-12-07T21:41:43.414112",
     "exception": false,
     "start_time": "2024-12-07T21:41:43.389565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# magic = \" 'it 's ' something Think A Human Plucrarealucrarealucrarealucrarealucrarealucrarealucrarealucrarea\"\n",
    "# # magic = \"\"\n",
    "# predictions = [f\"{x}\" for x in preds]\n",
    "\n",
    "sub = pd.read_csv(\"../input/llm-prompt-recovery/sample_submission.csv\")\n",
    "sub['rewrite_prompt'] = results\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 1455358,
     "sourceId": 2468672,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2740486,
     "sourceId": 4737381,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4524347,
     "sourceId": 7740846,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4524539,
     "sourceId": 7741042,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4572229,
     "sourceId": 7807215,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4634330,
     "sourceId": 7893017,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4645060,
     "sourceId": 7907523,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4663472,
     "sourceId": 7933949,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4689677,
     "sourceId": 7970245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4703298,
     "sourceId": 7989504,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4746640,
     "sourceId": 8049229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4681048,
     "sourceId": 8214346,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6225706,
     "sourceId": 10095386,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211730180,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 1902,
     "modelInstanceId": 3899,
     "sourceId": 5111,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 34183,
     "modelInstanceId": 23722,
     "sourceId": 28174,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 3301,
     "modelInstanceId": 8332,
     "sourceId": 28808,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 514.333483,
   "end_time": "2024-12-07T21:41:45.345986",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-07T21:33:11.012503",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0031bd3599cc41d396091ed455b4fecd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0865a8826f3449daa78566379ce4044d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_78a836cc5e0943de8f2e127901c71f1e",
       "placeholder": "​",
       "style": "IPY_MODEL_2a7e9a6ec7614ff8b5506d77d6c79fb6",
       "value": " 1/1 [00:00&lt;00:00, 51.92it/s]"
      }
     },
     "0943c2dc9ae14f8690950dac8dc94e32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c99736b218743cf8dbadc0de7955e99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7518b1a1cf3b41299d72705a429d7a08",
       "placeholder": "​",
       "style": "IPY_MODEL_d501fa8e20e344a1824cabbc21fdf733",
       "value": "Batches: 100%"
      }
     },
     "0dfceec6bb2949c8abda04a9b6d0210e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "16e276b6542d45608d5efca961f84880": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27aa849d2f18480e9975ec3a2249fa77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "292dc8791b8f409598962c453b4c94eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2a7e9a6ec7614ff8b5506d77d6c79fb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2e5eb4256dc1438a8b4377f663896401": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2ee350adbbac4a45bad8e2bd12ef2c86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_571048b66d1945d9b8bfc0e00c300f8a",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_89060e336917460d81879fb29113060b",
       "value": 1.0
      }
     },
     "2fb144b0efbc40f991225fa7b30de5e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0c99736b218743cf8dbadc0de7955e99",
        "IPY_MODEL_e48b2104bd4f4c9d8b3c83b3a1cf320c",
        "IPY_MODEL_458c4e18feac404a9ac1fe2d38de30fc"
       ],
       "layout": "IPY_MODEL_0dfceec6bb2949c8abda04a9b6d0210e"
      }
     },
     "3c8ff2d98b16474a9af440c8d7103d2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f20f9ea74af497b9f1471466488dc4b",
       "placeholder": "​",
       "style": "IPY_MODEL_292dc8791b8f409598962c453b4c94eb",
       "value": "Batches: 100%"
      }
     },
     "458c4e18feac404a9ac1fe2d38de30fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6f32ff7108f848fdbd305481c16c6c33",
       "placeholder": "​",
       "style": "IPY_MODEL_7ed14020eb8247fdb00fac939b8bc851",
       "value": " 1/1 [00:00&lt;00:00, 49.44it/s]"
      }
     },
     "51199f7c04d340d18d09d56a9c09a940": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "556c39b4a5a54f2ba1fcb6db21d6a96d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "571048b66d1945d9b8bfc0e00c300f8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6458202b25c24b6e93bea56289a87e6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3c8ff2d98b16474a9af440c8d7103d2f",
        "IPY_MODEL_c9e22971bfa34957be6c56b32664be97",
        "IPY_MODEL_9f1e0e367fcf4e128ccaf3b159e2a6a2"
       ],
       "layout": "IPY_MODEL_a0065fc645464e488a5aea3391b0202f"
      }
     },
     "6f32ff7108f848fdbd305481c16c6c33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71358ee395564ce2be377792f1debc7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "730872a935064001abdf4a2c32c29a41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7518b1a1cf3b41299d72705a429d7a08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78a836cc5e0943de8f2e127901c71f1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a6438efec4f4788bbaf2d861ddb40d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe19e5b0a14349dfa0984bf6169bc96d",
       "placeholder": "​",
       "style": "IPY_MODEL_71358ee395564ce2be377792f1debc7b",
       "value": " 1/1 [00:00&lt;00:00,  3.10it/s]"
      }
     },
     "7ed14020eb8247fdb00fac939b8bc851": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "89060e336917460d81879fb29113060b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8a9aeffdd9a44ac6b845ba47d4e3f727": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bfe5ce9f57c4314aab1152342fb22fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_556c39b4a5a54f2ba1fcb6db21d6a96d",
       "placeholder": "​",
       "style": "IPY_MODEL_0031bd3599cc41d396091ed455b4fecd",
       "value": "Batches: 100%"
      }
     },
     "8f20f9ea74af497b9f1471466488dc4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "911772b447b84fbb835ac7a5ffdab790": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bc68f7712eb45a898e5a6609f11ef58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c65c6c54b4754ecf863b17354dc2c782",
        "IPY_MODEL_2ee350adbbac4a45bad8e2bd12ef2c86",
        "IPY_MODEL_7a6438efec4f4788bbaf2d861ddb40d4"
       ],
       "layout": "IPY_MODEL_911772b447b84fbb835ac7a5ffdab790"
      }
     },
     "9f1e0e367fcf4e128ccaf3b159e2a6a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_730872a935064001abdf4a2c32c29a41",
       "placeholder": "​",
       "style": "IPY_MODEL_df9db1934e9b4bd29672c7ec115ca410",
       "value": " 1/1 [00:00&lt;00:00, 41.62it/s]"
      }
     },
     "a0065fc645464e488a5aea3391b0202f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bdd36d7eb3be4d4aa397941e0ff103b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8bfe5ce9f57c4314aab1152342fb22fd",
        "IPY_MODEL_d05fef2bfcde403e9b3343866a189b2e",
        "IPY_MODEL_0865a8826f3449daa78566379ce4044d"
       ],
       "layout": "IPY_MODEL_ee23779b41de4e9a9d5c53a8573f9788"
      }
     },
     "c356f69efebd4bed839421dae6b4947e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c65c6c54b4754ecf863b17354dc2c782": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a9aeffdd9a44ac6b845ba47d4e3f727",
       "placeholder": "​",
       "style": "IPY_MODEL_51199f7c04d340d18d09d56a9c09a940",
       "value": "Batches: 100%"
      }
     },
     "c9e22971bfa34957be6c56b32664be97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_27aa849d2f18480e9975ec3a2249fa77",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c356f69efebd4bed839421dae6b4947e",
       "value": 1.0
      }
     },
     "cd98f5325bbe41fdb1d3c8c18d8cde1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d05fef2bfcde403e9b3343866a189b2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0943c2dc9ae14f8690950dac8dc94e32",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2e5eb4256dc1438a8b4377f663896401",
       "value": 1.0
      }
     },
     "d501fa8e20e344a1824cabbc21fdf733": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "df9db1934e9b4bd29672c7ec115ca410": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e48b2104bd4f4c9d8b3c83b3a1cf320c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_16e276b6542d45608d5efca961f84880",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cd98f5325bbe41fdb1d3c8c18d8cde1c",
       "value": 1.0
      }
     },
     "ee23779b41de4e9a9d5c53a8573f9788": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe19e5b0a14349dfa0984bf6169bc96d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
