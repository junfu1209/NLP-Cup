{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T06:04:57.522246Z",
     "iopub.status.busy": "2024-12-04T06:04:57.521578Z",
     "iopub.status.idle": "2024-12-04T06:04:58.702408Z",
     "shell.execute_reply": "2024-12-04T06:04:58.701213Z",
     "shell.execute_reply.started": "2024-12-04T06:04:57.522159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl\n",
      "PyYAML-6.0.2-cp39-cp39-win_amd64.whl\n",
      "certifi-2024.8.30-py3-none-any.whl\n",
      "charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl\n",
      "colorama-0.4.6-py2.py3-none-any.whl\n",
      "filelock-3.16.1-py3-none-any.whl\n",
      "fsspec-2024.10.0-py3-none-any.whl\n",
      "huggingface_hub-0.26.3-py3-none-any.whl\n",
      "idna-3.10-py3-none-any.whl\n",
      "jinja2-3.1.4-py3-none-any.whl\n",
      "joblib-1.4.2-py3-none-any.whl\n",
      "mpmath-1.3.0-py3-none-any.whl\n",
      "networkx-3.2.1-py3-none-any.whl\n",
      "numpy-2.0.2-cp39-cp39-win_amd64.whl\n",
      "packaging-24.2-py3-none-any.whl\n",
      "pillow-11.0.0-cp39-cp39-win_amd64.whl\n",
      "regex-2024.11.6-cp39-cp39-win_amd64.whl\n",
      "requests-2.32.3-py3-none-any.whl\n",
      "safetensors-0.4.5-cp39-none-win_amd64.whl\n",
      "scikit_learn-1.5.2-cp39-cp39-win_amd64.whl\n",
      "scipy-1.13.1-cp39-cp39-win_amd64.whl\n",
      "sentence_transformers-3.3.1-py3-none-any.whl\n",
      "sympy-1.13.1-py3-none-any.whl\n",
      "threadpoolctl-3.5.0-py3-none-any.whl\n",
      "tokenizers-0.20.3-cp39-none-win_amd64.whl\n",
      "torch-2.5.1-cp39-cp39-win_amd64.whl\n",
      "tqdm-4.67.1-py3-none-any.whl\n",
      "transformers-4.46.3-py3-none-any.whl\n",
      "typing_extensions-4.12.2-py3-none-any.whl\n",
      "urllib3-2.2.3-py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "# !pip download sentence-transformers -d ./sentence_transformers/\n",
    "! ls ../input/sentence-transformers/sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T06:06:38.959738Z",
     "iopub.status.busy": "2024-12-04T06:06:38.959301Z",
     "iopub.status.idle": "2024-12-04T06:06:50.574812Z",
     "shell.execute_reply": "2024-12-04T06:06:50.573293Z",
     "shell.execute_reply.started": "2024-12-04T06:06:38.959697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/sentence-transformers/sentence_transformers\n",
      "Processing /kaggle/input/sentence-transformers/sentence_transformers/sentence_transformers-3.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers --no-index --find-links=file:/kaggle/input/sentence-transformers/sentence_transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-04T06:06:53.447987Z",
     "iopub.status.busy": "2024-12-04T06:06:53.447457Z",
     "iopub.status.idle": "2024-12-04T06:07:19.915905Z",
     "shell.execute_reply": "2024-12-04T06:07:19.914814Z",
     "shell.execute_reply.started": "2024-12-04T06:06:53.447937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import kagglehub\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, T5Tokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T06:07:27.779187Z",
     "iopub.status.busy": "2024-12-04T06:07:27.777482Z",
     "iopub.status.idle": "2024-12-04T06:07:28.221962Z",
     "shell.execute_reply": "2024-12-04T06:07:28.220662Z",
     "shell.execute_reply.started": "2024-12-04T06:07:27.779134Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The competition dataset comprises text passage...</td>\n",
       "      <td>Convert this into a sea shanty: \"\"\"The competi...</td>\n",
       "      <td>Here is your shanty: (Verse 1) The text is rew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      original_text  \\\n",
       "0  -1  The competition dataset comprises text passage...   \n",
       "\n",
       "                                      rewrite_prompt  \\\n",
       "0  Convert this into a sea shanty: \"\"\"The competi...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Here is your shanty: (Verse 1) The text is rew...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/llm-prompt-recovery/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/llm-prompt-recovery/test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "max_new_tokens = 30\n",
    "max_sentences_in_response = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/what5up/concat-prompts?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157k/157k [00:00<00:00, 348kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt_dataset\n",
    "path = kagglehub.dataset_download(\"what5up/concat-prompts\")\n",
    "files = os.listdir(path)\n",
    "csv_file = [file for file in files if file.endswith('.csv')][0]\n",
    "data = pd.read_csv(os.path.join(path, csv_file))\n",
    "prompt_dataset = data['prompt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d36337298c4a1cbc5ef19c69681de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de80e51340fb4f1b9c8c281cb9b65860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293d70434bf64376b4c823b02eeb3e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283cfc948a804af185aa8239c2e7236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary dataset\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"sentence-transformers/sentence-t5-base\")\n",
    "vocabulary_dataset = tokenizer.get_vocab()\n",
    "vocabulary_dataset.pop('<pad>', None)\n",
    "vocabulary_dataset.pop('</s>', None)\n",
    "vocabulary_dataset.pop('<unk>', None)\n",
    "vocabulary_dataset = list(vocabulary_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Convert the text into a vintage circus poster announcement', \"Convert the text into a social media platform's community guidelines\", 'Rewrite this as a college course description.', 'Rephrase this as a debate on furniture rights, featuring chairs.', \"Make the text into a home improvement expert's tips for a bathroom remodel\"]\n",
      "['▁', 'X', '.', ',', 's']\n"
     ]
    }
   ],
   "source": [
    "print(prompt_dataset[:5])\n",
    "print(vocabulary_dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotflip(prompt_tokens, token_index, vocabulary_dataset, model, target_embeddings):\n",
    "    possible_prompts = [' '.join(prompt_tokens[:token_index] + [vocab] + prompt_tokens[token_index + 1:]) for vocab in vocabulary_dataset]\n",
    "    prompt_embeddings = torch.tensor(np.array([model.encode(prompt) for prompt in possible_prompts]), dtype=torch.float32)\n",
    "\n",
    "    simularities = cosine_similarity(target_embeddings, prompt_embeddings)\n",
    "\n",
    "    vocab_index = simularities.argmax().item()\n",
    "    prompt_tokens[token_index] = vocabulary_dataset[vocab_index]\n",
    "\n",
    "    return prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac77ab42fce4ab2a4e078a4724376cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20243c9d9a54ae78aaf88dce04103f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbf447a604d47b8a855181fc3362972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498a8bf4495248139914db1f6a5932fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493259e60f764bb2be020272a9fa69ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdbfa39e50543e8a4c5204e6271d871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab6367ec06b40cfac108ec26d10a3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0379c03e08de40acbb7087dcb0b403a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6b4f8fd70c40eaab9d0668417fd7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6748ed31954efc828efadf19dceac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust_model.ot:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ba12fc9e6f4d24bb05e3f5a0fb78f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model\n",
    "model_name = \"sentence-transformers/sentence-t5-base\"\n",
    "model = SentenceTransformer(model_name)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Initial prompt\n",
    "prompt = \"Rewrite this text to make it more helpful\"\n",
    "prompt_embeddings = model.encode(prompt)\n",
    "prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# Prompt tokens\n",
    "prompt_tokens = prompt.split(' ')\n",
    "\n",
    "# Target\n",
    "target_embeddings = model.encode(prompt_dataset)\n",
    "target_embeddings = torch.tensor(target_embeddings, dtype=torch.float32).mean(dim=0).unsqueeze(0)\n",
    "\n",
    "print(prompt_embeddings.shape)\n",
    "print(target_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.041653215885162354\n",
      "<extra_id_20> ▁Alter ▁sentences lucrarea ▁Make ▁fiction ▁proposal ▁vibe\n"
     ]
    }
   ],
   "source": [
    "# output 固定\n",
    "fixed_output=''\n",
    "for epoch in range(EPOCHS):\n",
    "    for token_index in range(len(prompt_tokens)):\n",
    "        loss =  1 - cosine_similarity(target_embeddings, prompt_embeddings)\n",
    "        prompt_tokens = hotflip(prompt_tokens, token_index, vocabulary_dataset, model, target_embeddings)\n",
    "        prompt = ' '.join(prompt_tokens)\n",
    "        prompt_embeddings = model.encode(prompt)\n",
    "        prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "    print(prompt)\n",
    "    # output 設定為 meam prompt\n",
    "    fixed_output = prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 將所有樣本的 rewrite_prompt 設定為 meam prompt\n",
    "test_df['rewrite_prompt'] = [fixed_output] * len(train_df)\n",
    "test_df[['id', 'rewrite_prompt']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df[['id', 'rewrite_prompt']].to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 1455358,
     "sourceId": 2468672,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2266900,
     "sourceId": 3814409,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4572229,
     "sourceId": 7807215,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6225706,
     "sourceId": 10095386,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 27,
     "modelInstanceId": 284,
     "sourceId": 386,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
